{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import FeatureHasher, StringIndexer, OneHotEncoder, VectorAssembler\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "                    .appName(\"Assignment2_H3\")\\\n",
    "                    .master(\"local[*]\")\\\n",
    "                    .config('spark.executor.memory','64g')\\\n",
    "                    .config('spark.driver.memory','32g')\\\n",
    "                    .config('spark.driver.maxResultSize','2g')\\\n",
    "                    .config('spark.default.parallelism','300')\\\n",
    "                    .config('spark.network.timeout','500')\\\n",
    "                    .getOrCreate()\n",
    "\n",
    "\n",
    "df = spark.read\\\n",
    "    .format(\"jdbc\")\\\n",
    "    .option(\"url\", \"\")\\\n",
    "    .option(\"dbtable\", \"citizen\") \\\n",
    "    .option(\"user\", \"postgres\")\\\n",
    "    .option(\"password\", \"postgres\")\\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- uid: long (nullable = true)\n",
      " |-- national_identifier: long (nullable = true)\n",
      " |-- first: string (nullable = true)\n",
      " |-- last: string (nullable = true)\n",
      " |-- mother_first: string (nullable = true)\n",
      " |-- father_first: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- birth_city: string (nullable = true)\n",
      " |-- date_of_birth: date (nullable = true)\n",
      " |-- id_registration_city: string (nullable = true)\n",
      " |-- id_registration_district: string (nullable = true)\n",
      " |-- address_city: string (nullable = true)\n",
      " |-- address_district: string (nullable = true)\n",
      " |-- address_neighborhood: string (nullable = true)\n",
      " |-- street_address: string (nullable = true)\n",
      " |-- door_or_entrance_number: integer (nullable = true)\n",
      " |-- misc: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preprocession: Convert the type of columns\n",
    "from pyspark.sql.functions import to_date,year,month,dayofmonth\n",
    "pattern = 'd/M/y'\n",
    "df = df.withColumn('date_of_birth',to_date(df['date_of_birth'],pattern))\n",
    "df = df.withColumn('national_identifier',df.national_identifier.cast('long'))\n",
    "df = df.withColumn('door_or_entrance_number',df.door_or_entrance_number.cast('int'))\n",
    "df = df.withColumn('year',year('date_of_birth'))\n",
    "df = df.withColumn('month',month('date_of_birth'))\n",
    "df = df.withColumn('day',dayofmonth('date_of_birth'))\n",
    "df.printSchema()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H3. Surname prediction model\n",
    "Given all the information about a person (except the surname), predict the most likely surname of that person. Analyze the prediction accuracy of this model Top1 to Top 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3p = df.limit(40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[uid: bigint, national_identifier: bigint, first: string, last: string, mother_first: string, father_first: string, gender: string, birth_city: string, date_of_birth: date, id_registration_city: string, id_registration_district: string, address_city: string, address_district: string, address_neighborhood: string, street_address: string, door_or_entrance_number: int, misc: string, year: int, month: int, day: int]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3p.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index the label\n",
    "label = 'last'\n",
    "labelIdx = StringIndexer(inputCol=label, outputCol='last_int', handleInvalid='skip')\n",
    "labelIdxModel = labelIdx.fit(df3p)\n",
    "df3p = labelIdxModel.transform(df3p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### df3p.rdd.getNumPartitions()\n",
    "# 08:14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction\n",
    "\n",
    "# # Remove label column and invalid columns.\n",
    "# features = df3p.columns\n",
    "# features.remove('last_int')\n",
    "# features.remove('misc')\n",
    "# features.remove('date_of_birth')\n",
    "features = ['mother_first','father_first']\n",
    "for i in features:\n",
    "    labelIdx = StringIndexer(inputCol=i, outputCol=i + '_int', handleInvalid='skip')\n",
    "    labelIdxModel = labelIdx.fit(df3p)\n",
    "    df3p = labelIdxModel.transform(df3p)\n",
    "\n",
    "df3v = df3p\n",
    "for i in features:\n",
    "    encoder = OneHotEncoder(inputCol = i + '_int', outputCol = i + '_vec')\n",
    "    df3v = encoder.fit(df3v).transform(df3v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VectorAssembler\n",
    "vecAssembler = VectorAssembler(outputCol=\"features\")\n",
    "vecAssembler.setInputCols(['mother_first_int','father_first_int'])\n",
    "df3v = vecAssembler.transform(df3v)\n",
    "\n",
    "df3v.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# Vectorize the feature\n",
    "# hasher3 = FeatureHasher(numFeatures=3)\n",
    "# hasher3.setInputCols(features).setOutputCol(\"features\")\n",
    "# df3v = hasher3.transform(df3p)\n",
    "# df3v = df3v.select('features','last','last_int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "train_dat, valid_dat, test_dat = df3v.randomSplit([0.7, 0.1, 0.2],seed=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Feature Selection\n",
    "# from pyspark.ml.feature import ChiSqSelector\n",
    "# slctor3 = ChiSqSelector(numTopFeatures = 2,featuresCol='features',outputCol='selectFeatures',labelCol='last_int')\n",
    "# slctorModel3 = slctor3.fit(train_dat)\n",
    "\n",
    "# selectIdx = slctorModel3.selectedFeatures\n",
    "# selectIdx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "nb3 = NaiveBayes(smoothing=1.0, modelType=\"multinomial\")\n",
    "nb3.setLabelCol('last_int').setFeaturesCol(\"features\")\n",
    "model3 = nb3.fit(train_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model3.transform(valid_dat).select('last_int','probability').rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top1 to Top5 accuracy\n",
    "def accuracy_per(level, prob, label):\n",
    "    miss = 0\n",
    "    a = 0\n",
    "    label_prob = prob[label]\n",
    "    for p in prob:\n",
    "        if p > label_prob:\n",
    "            a = a+1\n",
    "        if a >= level:\n",
    "            miss = 1\n",
    "            break\n",
    "    return miss\n",
    "\n",
    "topK = []\n",
    "for i in range(1,6):\n",
    "    topK.append(res.map(lambda x:(1,accuracy_per(i, x[1].toArray() ,int(x[0]))))\\\n",
    "                        .reduce(lambda x,y:(x[0]+y[0],x[1]+y[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(topK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    print('The top', i ,'accuracy is', 1 - topK[i][1]/topK[i][0], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter Tunning\n",
    "\n",
    "# from pyspark.ml.tuning import ParamGridBuilder\n",
    "# layers = [128,64,8,2]\n",
    "# layers2 = [64,8,4,2]\n",
    "# paramGrid2 = (ParamGridBuilder()\n",
    "#             .addGrid(mlp2.layers, [layers,layers2])\n",
    "#             .build())\n",
    "\n",
    "# from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "# evaluator2 = BinaryClassificationEvaluator(labelCol='gender_int',rawPredictionCol='prediction')\n",
    "\n",
    "# from pyspark.ml.tuning import CrossValidator\n",
    "# cv2 = CrossValidator(estimator = nb2,\n",
    "#                     evaluator = evaluator2,\n",
    "#                     estimatorParamMaps=paramGrid2,\n",
    "#                     numFolds=3,\n",
    "#                     parallelism=2,\n",
    "#                     seed=1234)\n",
    "\n",
    "# genderModel = cv2.fit(valid_dat2)\n",
    "\n",
    "# evaluator2.evaluate(genderModel.transform(test_dat2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
